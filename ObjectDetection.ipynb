{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\">The Sparks Foundations IoT & Computer Vision intern </div>\n",
    "\n",
    "## <center>Task 1: Object Detetion  </center>\n",
    "<div style=\"text-align: right\"> <font size=4>\n",
    "By: Md. Yeasin Sheikh</font> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using MobilNet-SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages we need \n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are using cv 4.5.1\n"
     ]
    }
   ],
   "source": [
    "print('we are using cv', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of objects that can be detected using this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames= []\n",
    "classFilePath = 'data/coco.names'\n",
    "with open(classFilePath,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects that can be Detected:  91\n",
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'hair brush']\n"
     ]
    }
   ],
   "source": [
    "print('Number of objects that can be Detected: ', len(classNames))\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dnn Detection Model \n",
    "locating the trained model class path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 000002D24D80E550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configPath = 'data/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'data/frozen_inference_graph.pb'\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets'  test on an image\n",
    "importing image from assets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1580, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('assets/dogCat.png')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This image kinda big, let's Resize it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize a bit \n",
    "imgHeight, imgWidth, _ = img.shape\n",
    "scale= 60\n",
    "imgH = int (imgHeight *scale /100)\n",
    "imgW = int (imgWidth * scale /100)\n",
    "img = cv2.resize(img, (imgW, imgH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets' declear some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectColor =(244,5,20)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "fontSize = 1\n",
    "fontColor = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Threshold to detect object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.45 # Threshold to detect object\n",
    "nms_thres = .5 # 0-1 higer value means lower suppress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "type(confs),type(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating for non-maxima suppression\n",
    "<font size=4> it removes overlap bounding boxes & keep the most confident ones.</font>\n",
    "<font size=3> make sure bounding boxex and confident are List of floats, it shouldn't associate with numpy \n",
    "    </font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bjects we get:  2\n"
     ]
    }
   ],
   "source": [
    "bbox = list(bbox)\n",
    "confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "confs = list(map(float,confs ))\n",
    "\n",
    "indics = cv2.dnn.NMSBoxes(bbox, confs, thres, nms_thres) # remove overlaps\n",
    "print('Number of bjects we get: ',len(indics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5> Take a look on actual image</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat  conf  82.1\n",
      "dog  conf  76.0\n"
     ]
    }
   ],
   "source": [
    "for ind in indics:\n",
    "    i = ind[0] # ind returns list we need index only\n",
    "    box = bbox[i]\n",
    "    \n",
    "    cv2.rectangle(img, box, rectColor, 1) #set the rectangle around object\n",
    "    \n",
    "    obj_name = classNames[classIds[i][0]-1]\n",
    "    obj_confidences = round(confs[i]*100, 1)\n",
    "    print(obj_name, \" conf \", str(obj_confidences))\n",
    "    \n",
    "    if obj_confidences>56:\n",
    "        #show accuracy level\n",
    "        cv2.putText(img, str(obj_confidences), (box[0]+10, box[1]+10), \n",
    "                   font, fontSize, fontColor, 1,cv2.LINE_AA)\n",
    "    \n",
    "        #putting name of object \n",
    "        cv2.putText(img, obj_name.upper(), (box[0]+70, box[1]+10), \n",
    "                   font, fontSize, fontColor,1,cv2.LINE_AA)\n",
    "    \n",
    "# Lets show the result \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test it on webcam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0) # my webcam id\n",
    "# cam = cv2.VideoCapture('assets/testVideo.mp4') # my webcam id\n",
    "cam.set(3, 1000) # width of camView\n",
    "cam.set(4, 800) # height of camView\n",
    "cam.set(10, 150) # brightness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also make a funtion just for image processing \n",
    "while True:\n",
    "    success, img = cam.read()\n",
    "    if success:\n",
    "        classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "        \n",
    "        #Formating data\n",
    "        bbox = list(bbox)\n",
    "        confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "        confs = list(map(float,confs ))\n",
    "\n",
    "        indics = cv2.dnn.NMSBoxes(bbox, confs, thres, nms_thres) # remove overlaps\n",
    "        \n",
    "        for ind in indics:\n",
    "            i = ind[0] # ind returns list we need index only\n",
    "            box = bbox[i]\n",
    "    \n",
    "            cv2.rectangle(img, box, rectColor, 1) #set the rectangle around object\n",
    "    \n",
    "            #show accuracy level\n",
    "            cv2.putText(img, str(round(confs[i]*100, 1)), (box[0]+10, box[1]+10), \n",
    "                       font, fontSize, fontColor, 1)\n",
    "            #putting name of object \n",
    "            cv2.putText(img, classNames[classIds[i][0]-1], (box[0]+70, box[1]+30), \n",
    "                       font, fontSize, fontColor,1)\n",
    "        \n",
    "    \n",
    "        cv2.imshow(\"Object detection\", img)\n",
    "        if cv2.waitKey(1) == 27: \n",
    "            break  # esc to quit\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Thanks for your time ðŸ˜Š</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
