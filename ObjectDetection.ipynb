{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are using pretrained model ssd_mobilenet_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages we need \n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are using cv 4.5.1\n"
     ]
    }
   ],
   "source": [
    "print('we are using cv', cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of objects that can be detected using this model\n",
    "#### names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames= []\n",
    "classFilePath = 'ot/coco.names'\n",
    "with open(classFilePath,'rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects that can be Detected:  91\n",
      "['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush', 'hair brush']\n"
     ]
    }
   ],
   "source": [
    "print('Number of objects that can be Detected: ', len(classNames))\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dnn Detection Model \n",
    "locating the trained model class path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dnn_Model 00000254D88E3F90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configPath = 'ot/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'ot/frozen_inference_graph.pb'\n",
    "\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/ 127.5)\n",
    "net.setInputMean((127.5, 127.5, 127.5))\n",
    "net.setInputSwapRB(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets'  test on an image\n",
    "importing image from assets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3041, 5406, 3)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('assets/ocean.jpg')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This image too big for screen, let's Resize it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize a bit \n",
    "imgHeight, imgWidth, _ = img.shape\n",
    "scale= 30\n",
    "imgH = int (imgHeight *scale /100)\n",
    "imgW = int (imgWidth * scale /100)\n",
    "img = cv2.resize(img, (imgW, imgH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets' declear some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rectColor =(244,0,0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX\n",
    "fontSize = 1\n",
    "fontColor = (200, 200, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Threshold to detect object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.45 # Threshold to detect object\n",
    "nms_thres = .5 # 0-1 higer value means lower suppress "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "type(confs),type(bbox)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formating for nms, its remove overlap\n",
    "<fonr size=3> make sure bbox is list<float> and confs is also List<float> ,we dont want anything associate with numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "bbox = list(bbox)\n",
    "confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "confs = list(map(float,confs ))\n",
    "\n",
    "indics = cv2.dnn.NMSBoxes(bbox, confs, thres, nms_thres) # remove overlaps\n",
    "print(indics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in indics:\n",
    "    i = ind[0] # ind returns list we need index only\n",
    "    box = bbox[i]\n",
    "    \n",
    "    cv2.rectangle(img, box, rectColor, 1) #set the rectangle around object\n",
    "    \n",
    "    #show accuracy level\n",
    "    cv2.putText(img, str(round(confs[i]*100, 1)), (box[0]+10, box[1]+10), \n",
    "               font, fontSize, fontColor, 1)\n",
    "    #putting name of object \n",
    "    cv2.putText(img, classNames[classIds[i][0]-1], (box[0]+70, box[1]+30), \n",
    "               font, fontSize, fontColor,1)\n",
    "    \n",
    "# Lets show the result \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test it on webcam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0) # my webcam id\n",
    "cam.set(3, 600) # width of camView\n",
    "cam.set(4, 400) # height of camView\n",
    "cam.set(10, 100) # brightness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    success, img = cam.read()\n",
    "    if success:\n",
    "        classIds, confs, bbox = net.detect(img,confThreshold=thres)\n",
    "        \n",
    "        #Formating data\n",
    "        bbox = list(bbox)\n",
    "        confs = list(np.array(confs).reshape(1, -1)[0])\n",
    "        confs = list(map(float,confs ))\n",
    "\n",
    "        indics = cv2.dnn.NMSBoxes(bbox, confs, thres, nms_thres) # remove overlaps\n",
    "        \n",
    "        for ind in indics:\n",
    "            i = ind[0] # ind returns list we need index only\n",
    "            box = bbox[i]\n",
    "    \n",
    "            cv2.rectangle(img, box, rectColor, 1) #set the rectangle around object\n",
    "    \n",
    "            #show accuracy level\n",
    "            cv2.putText(img, str(round(confs[i]*100, 1)), (box[0]+10, box[1]+10), \n",
    "                       font, fontSize, fontColor, 1)\n",
    "            #putting name of object \n",
    "            cv2.putText(img, classNames[classIds[i][0]-1], (box[0]+70, box[1]+30), \n",
    "                       font, fontSize, fontColor,1)\n",
    "        \n",
    "    \n",
    "        cv2.imshow(\"Object detection\", img)\n",
    "    cv2.waitKey(10)\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
